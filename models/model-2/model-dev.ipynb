{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Takes as input the (768, 768, 64) images from `dataset-1`.\n",
    "- It takes 4^3 average across the 2D, and average across the depth\n",
    "- This results in a (192, 192, 16) volume.\n",
    "- I have a image that is of shape (1, 192, 192, 16). Divide the image and the labels into 32 patches: (1, 8*24, 8*24, 16) → (24, 24, 1024) → (576, 1024). \n",
    "- Pass the image into a transformer architecture with 6 layers, which will return (576, 1) tensor, which corresponds to probabilities of pixel occuring. You should also pass the “positional embeddings”, which should be of dimension 1024."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4^3 3D average \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def avg_3d(volume):\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    volume_tensor = torch.tensor(volume, dtype=torch.float32)\n",
    "\n",
    "    # Add batch and channel dimensions to the tensor\n",
    "    volume_tensor = volume_tensor.permute(0, 3, 1, 2)  # Reorder dimensions to (batch, channels, height, width)\n",
    "\n",
    "    # Create the 3D average pooling layer with the appropriate kernel size and stride values\n",
    "    avg_pool = nn.AvgPool3d(kernel_size=4, stride=4, padding=0)\n",
    "\n",
    "    # Apply the average pooling layer to the input tensor\n",
    "    with torch.no_grad():\n",
    "        filtered_volume_tensor = avg_pool(volume_tensor)\n",
    "\n",
    "    # Convert the output tensor back to a numpy array\n",
    "    filtered_volume = filtered_volume_tensor.permute(0, 2, 3, 1)  # Reorder dimensions back to (batch, height, width, channels)\n",
    "    \n",
    "    return filtered_volume\n",
    "\n",
    "\n",
    "# Example volume\n",
    "volume = np.random.rand(1, 768, 768, 64)\n",
    "volume_avgd = avg_3d(volume)\n",
    "# %time avg_3d(volume) # 85 ms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 192, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_avgd.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take random 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 192, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_avgd_new = volume_avgd.permute(3, 1, 2, 0)\n",
    "# take 3 random numbers between 0 and 16, without replacement\n",
    "random_numbers = np.random.choice(16, 3, replace=False)\n",
    "volume_avgd_new = volume_avgd_new[random_numbers, :, :, :]\n",
    "# Repermute\n",
    "volume_avgd_new = volume_avgd_new.permute(3, 1, 2, 0)\n",
    "volume_avgd_new.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 576, 1024])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def reshape_img(image):\n",
    "    # Calculate the size of each patch\n",
    "    patch_size = 24\n",
    "\n",
    "    B, H, W, C = image.shape\n",
    "    image = image.reshape(B, H // patch_size, patch_size, W // patch_size, patch_size, C) # (B, 8, 24, 8, 24, 16)\n",
    "    image = image.permute(0, 2, 4, 1, 3, 5) # (B, 24, 24, 8, 8, 16)\n",
    "    image = image.reshape(B, patch_size, patch_size, -1) # (B, 24, 24, 1024)\n",
    "    image = image.reshape(B, -1, 1024) # (B, 576, 1024)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Example image\n",
    "image = np.random.rand(2, 192, 192, 16)\n",
    "image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "\n",
    "image = reshape_img(image)\n",
    "\n",
    "print(image.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0point5_score(output, target):\n",
    "    # Flatten the output and target tensors\n",
    "    output = output.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    # Convert the output to binary values 0 and 1\n",
    "    output = (output > 0.5).float()\n",
    "    \n",
    "    # Calculate the precision and recall\n",
    "    tp = torch.sum(output * target)\n",
    "    fp = torch.sum(output * (1 - target))\n",
    "    fn = torch.sum((1 - output) * target)\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "    \n",
    "    # Calculate the F0.5 score\n",
    "    beta = 0.5\n",
    "    f0point5 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-7)\n",
    "    return f0point5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: ResNet50Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNet50Seg(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, class_one_weight=1):\n",
    "        super(ResNet50Seg, self).__init__()\n",
    "        \n",
    "        self.class_one_weight = class_one_weight\n",
    "        \n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet50 = models.resnet50()\n",
    "        \n",
    "        # Replace the final layer to output 1024 channel instead of 1000\n",
    "        self.resnet50.fc = nn.Linear(2048, 1024)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.resnet50(x)\n",
    "        # Apply sigmoid\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        out = {}\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "            precision = None\n",
    "            accuracy = None\n",
    "            f0point5 = None\n",
    "        else:\n",
    "            # Calculate the loss\n",
    "            \n",
    "            # Calculate class weights based on the imbalance\n",
    "            class_weights = torch.tensor([1.0, self.class_one_weight]) # weight 1 for class 0, weight 5 for class 1\n",
    "\n",
    "            # Instantiate the loss function\n",
    "            loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights[1], reduction='mean')\n",
    "            \n",
    "            # Flatten the targets tensor\n",
    "            targets = targets.reshape(-1, 1024)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = loss_function(x, targets)\n",
    "            \n",
    "            # Calculate the accuracy: number of correctly predicted pixel / total number of pixels\n",
    "            # Convert the predictions to binary values 0 and 1\n",
    "            predictions = (x > 0.5).float()\n",
    "            # Calculate the accuracy\n",
    "            accuracy = (predictions == targets).float().mean()\n",
    "            \n",
    "            # Calculate the precision\n",
    "            tp = torch.sum(predictions * targets)   \n",
    "            fp = torch.sum(predictions * (1 - targets))\n",
    "            fn = torch.sum((1 - predictions) * targets)\n",
    "            precision = tp / (tp + fp + 1e-7)\n",
    "            \n",
    "            # Calculate F0.5 score\n",
    "            f0point5 = f0point5_score(predictions, targets) \n",
    "        \n",
    "        out = {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": x,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"f0point5\": f0point5\n",
    "        }\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50Seg(in_channels=3, out_channels=1)\n",
    "x = torch.randn(1, 3, 192, 192)  # input image\n",
    "output = model(x)\n",
    "output['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.606208"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of 1e6 parameters\n",
    "sum(p.numel() for p in model.parameters()) / 1e6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.2220],\n",
       "         [2.9907],\n",
       "         [1.2412],\n",
       "         [1.7058],\n",
       "         [0.6931]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate class weights based on the imbalance\n",
    "class_weights = torch.tensor([1.0, 5.0]) # weight 1 for class 0, weight 5 for class 1\n",
    "\n",
    "# Instantiate the loss function\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights[1], reduction='none')\n",
    "\n",
    "# Example output and targets\n",
    "out = [[0.1], [0.2], [0.9], [0.9], [0]]\n",
    "tar = [[1], [1], [0], [1], [0]]\n",
    "output = torch.tensor([out], dtype=torch.float32)\n",
    "targets = torch.tensor([tar], dtype=torch.float32)\n",
    "loss_function(output, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9705)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate class weights based on the imbalance\n",
    "class_weights = torch.tensor([1.0, 5.0]) # weight 1 for class 0, weight 5 for class 1\n",
    "\n",
    "# Instantiate the loss function\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights[1], reduction='mean')\n",
    "\n",
    "# Example output and targets\n",
    "out = [[0.1], [0.2], [0.9], [0.9], [0]]\n",
    "tar = [[1], [1], [0], [1], [0]]\n",
    "output = torch.tensor([out], dtype=torch.float32)\n",
    "targets = torch.tensor([tar], dtype=torch.float32)\n",
    "loss_function(output, targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with loss test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1024]),\n",
       " tensor(0.8201, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor(0.3237))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50Seg(in_channels=3, out_channels=1)\n",
    "x = torch.randn(16, 3, 192, 192)  # input image\n",
    "targets = torch.randn(16, 1024)  # input image\n",
    "\n",
    "# Normalize x to be between 0 and 1\n",
    "x = torch.sigmoid(x)\n",
    "\n",
    "# Clip targets to 0 and 1\n",
    "targets = torch.clamp(targets, 0, 1)\n",
    "\n",
    "\n",
    "output = model(x, targets)\n",
    "output['logits'].shape, output['loss'], output['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8094)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected value for the BCE loss if there is 1024 elements\n",
    "\n",
    "# Instantiate the loss function\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights[1], reduction='mean')\n",
    "\n",
    "y_true = torch.randn(1024, 1024) \n",
    "y_pred = torch.randn(1024, 1024) \n",
    "\n",
    "loss = loss_function(y_pred, y_true)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1933)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected value for the BCE loss if there is 1024 elements that were all correctly classified\n",
    "\n",
    "# Instantiate the loss function\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights[1], reduction='mean')\n",
    "\n",
    "y_pred = torch.randn(1024*16, 1024) \n",
    "\n",
    "loss = loss_function(y_pred, y_pred)\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit on 1 batch of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/450 [00:00<03:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1121, Accuracy: 0.4919, Precision: 0.0982, F0.5: 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/450 [00:03<02:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0670, Accuracy: 0.6594, Precision: 0.2008, F0.5: 0.2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 21/450 [00:06<02:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0315, Accuracy: 0.7725, Precision: 0.2935, F0.5: 0.3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/450 [00:09<02:22,  2.95it/s][E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "  7%|▋         | 30/450 [00:09<02:19,  3.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb Cell 24\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viktorcikojevic/Insync/cikojevic.viktor%40gmail.com/Google%20Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m f0point5 \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mf0point5\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viktorcikojevic/Insync/cikojevic.viktor%40gmail.com/Google%20Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/viktorcikojevic/Insync/cikojevic.viktor%40gmail.com/Google%20Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viktorcikojevic/Insync/cikojevic.viktor%40gmail.com/Google%20Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viktorcikojevic/Insync/cikojevic.viktor%40gmail.com/Google%20Drive/Kaggle/vesuvius-challenge/models/model-2/model-dev.ipynb#X30sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = ResNet50Seg(in_channels=3, out_channels=1, class_one_weight=5)\n",
    "x = torch.randn(4, 3, 192, 192)  # input image\n",
    "# targets = random integers of shape (4, 1024) between 0 and 1\n",
    "targets = torch.randint(0, 2, (4, 1024)).float()\n",
    "# Make 80% of the targets to be 0\n",
    "targets[:, 0:819] = 0\n",
    "\n",
    "\n",
    "# Normalize x to be between 0 and 1\n",
    "x = torch.sigmoid(x)\n",
    "\n",
    "# Clip targets to 0 and 1\n",
    "targets = torch.clamp(targets, 0, 1)\n",
    "\n",
    "# optimizer \n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "n_iters = 450\n",
    "for i in tqdm(range(n_iters)):\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x, targets)\n",
    "    loss = output['loss']\n",
    "    precision = output['precision']\n",
    "    accuracy = output['accuracy']\n",
    "    f0point5 = output['f0point5']\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}, Precision: {precision.item():.4f}, F0.5: {f0point5.item():.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import avg_pool2d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class ImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, root, mode='train', device='cpu', cache_refresh_interval=None, cache_n_images=64):\n",
    "        \n",
    "        assert mode in ['train', 'test'], \"mode must be either 'train' or 'test'\"\n",
    "        \n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.cache_refresh_interval = cache_refresh_interval\n",
    "        self.cache_n_images = cache_n_images\n",
    "        self._load_data()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.volume_images)\n",
    "    \n",
    "    # def __getitem__(self, item):\n",
    "        \n",
    "    #     volume = np.load(self.volume_images[item])\n",
    "    #     label = np.load(self.label_images[item])\n",
    "        \n",
    "    #     # convert to torch tensors\n",
    "    #     volume = torch.tensor(volume, dtype=torch.float32)\n",
    "    #     label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "    #     # send to device\n",
    "    #     volume = volume.to(self.device)\n",
    "    #     label = label.to(self.device)\n",
    "        \n",
    "    #     # unsqueeze the channel dimension\n",
    "    #     label = label.unsqueeze(-1)\n",
    "        \n",
    "        \n",
    "    #     # take one random number from 0 to 20, 20 to 35, 35 to 50, 50 to 64\n",
    "    #     idx_1 = np.random.randint(0, 20)\n",
    "    #     idx_2 = np.random.randint(20, 35)\n",
    "    #     idx_3 = np.random.randint(35, 50)\n",
    "    #     indices = [idx_1, idx_2, idx_3]\n",
    "    #     volume = volume[:, :, indices]\n",
    "        \n",
    "    #     # Apply 2D average pooling to the volume and label tensors\n",
    "    #     # Average each channel separately\n",
    "    #     volume = volume.permute(2, 0, 1)  # Permute dimensions for avg_pool2d\n",
    "    #     volume = avg_pool2d(volume, kernel_size=4, stride=4)\n",
    "    #     volume = volume.permute(1, 2, 0)  # Permute dimensions back\n",
    "        \n",
    "    #     label = label.permute(2, 0, 1)  # Permute dimensions for avg_pool2d\n",
    "    #     label = avg_pool2d(label, kernel_size=4, stride=4)\n",
    "    #     label = label.permute(1, 2, 0)  # Permute dimensions back\n",
    "        \n",
    "    #     return {\n",
    "    #         \"image\": volume,\n",
    "    #         \"targets\": label\n",
    "    #     }\n",
    "       \n",
    "    def _load_data(self):\n",
    "        # Get the volume paths\n",
    "        self.volume_images = os.listdir(os.path.join(self.root, self.mode, 'volume'))\n",
    "        self.volume_images = [os.path.join(self.root, self.mode, 'volume', image) for image in self.volume_images]\n",
    "        \n",
    "        # Get label paths\n",
    "        self.label_images = os.listdir(os.path.join(self.root, self.mode, 'label'))\n",
    "        self.label_images = [os.path.join(self.root, self.mode, 'label', image) for image in self.label_images]\n",
    "        \n",
    "        # take self.cache_n_images random images from the dataset. They cannot be repeated\n",
    "        if self.cache_n_images is not None and self.cache_n_images < len(self.volume_images):\n",
    "            self.volume_images = np.random.choice(self.volume_images, size=self.cache_n_images, replace=False)\n",
    "            self.label_images = np.random.choice(self.label_images, size=self.cache_n_images, replace=False)\n",
    "        \n",
    "        # Load the data into memory\n",
    "        self.cached_data = []\n",
    "        for volume_image, label_image in zip(self.volume_images, self.label_images):\n",
    "            volume = np.load(volume_image)\n",
    "            label = np.load(label_image)\n",
    "            \n",
    "            # convert to torch tensors\n",
    "            volume = torch.tensor(volume, dtype=torch.float32)\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            self.cached_data.append({\n",
    "                \"image\": volume,\n",
    "                \"targets\": label\n",
    "            }) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cached_data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.cached_data[item]\n",
    "    \n",
    "    def refresh_cache(self):\n",
    "        self._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the dataset and dataloader\n",
    "root = \"../../datasets/dataset-1/\"\n",
    "\n",
    "# Mac m1 device\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dataset = ImageSegmentationDataset(root=root, mode='train', device=device, cache_refresh_interval=160, cache_n_images=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 192, 192, 3]), torch.Size([5, 192, 192, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one batch\n",
    "batch = next(iter(dataloader))\n",
    "batch['image'].shape, batch['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 100 iterations: 0.0349 seconds\n"
     ]
    }
   ],
   "source": [
    "# Let's check how fast the dataloader is\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    batch = next(iter(dataloader))\n",
    "    # Refresh the cache \n",
    "    if i % dataset.cache_refresh_interval == 0:\n",
    "        dataset.refresh_cache()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken for 100 iterations: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.1 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.load(\"/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/datasets/dataset-1/train/volume/0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 64)\n",
      "(192, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.load(\"/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/datasets/dataset-1/train/volume/0.npy\")\n",
    "print(x.shape)\n",
    "x = x[::4, ::4, :3]\n",
    "print(x.shape)\n",
    "np.save(\"/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/datasets/dataset-1/train/tmp/x.npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 µs ± 2.63 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.load(\"/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/datasets/dataset-1/train/tmp/x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 µs ± 14.2 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.load(\"/Users/viktorcikojevic/Insync/cikojevic.viktor@gmail.com/Google Drive/Kaggle/vesuvius-challenge/datasets/dataset-1/train/label/0.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: make it's best to generate dataset-1 by taking 4x4 avg_2d while creating the dataset. This will make the dataloader much much faster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
