{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "def load_into_3d_array(folder_path, z_start, z_end, new_img_size=3000):\n",
    "    # Initialize an empty list to hold 2D image slices\n",
    "    slices = []\n",
    "    \n",
    "    # Sort the files to load them in order\n",
    "    files = sorted(os.listdir(folder_path))\n",
    "    \n",
    "    # Load first one and check the shape\n",
    "    filepath = os.path.join(folder_path, files[z_start])\n",
    "    img_slice = tifffile.imread(filepath)\n",
    "    \n",
    "    new_img_size = 3000\n",
    "    img_size_x, img_size_y = img_slice.shape\n",
    "    random_offset_x = np.random.randint(0, img_size_x - new_img_size)\n",
    "    random_offset_y = np.random.randint(0, img_size_y - new_img_size)\n",
    "    slices = [img_slice[random_offset_x:random_offset_x+new_img_size, random_offset_y:random_offset_y+new_img_size]]\n",
    "    \n",
    "    for file in files[z_start+1:z_end]:\n",
    "        if file.endswith('.tif'):\n",
    "            filepath = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Read a .tif image file\n",
    "            img_slice = tifffile.imread(filepath)[random_offset_x:random_offset_x+new_img_size, random_offset_y:random_offset_y+new_img_size]\n",
    "            \n",
    "            # Append to list\n",
    "            slices.append(img_slice)\n",
    "            \n",
    "    # Stack along a new third dimension to make a 3D array\n",
    "    stack = np.stack(slices, axis=2)\n",
    "    \n",
    "    return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 ms ± 14.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage\n",
    "folder_path = '/home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/1/surface_volume'  # Replace with the path to your 'surface_volume' folder\n",
    "%timeit three_d_array = load_into_3d_array(folder_path, z_start=8, z_end=18) # ~ 500ms per loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3778569/3872868104.py:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  mask_data = imageio.imread(mask_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 00.tif\n",
      "Processing 01.tif\n",
      "Processing 02.tif\n",
      "Processing 03.tif\n",
      "Processing 04.tif\n",
      "Processing 05.tif\n",
      "Processing 06.tif\n",
      "Processing 07.tif\n",
      "Processing 08.tif\n",
      "Processing 09.tif\n",
      "Processing 10.tif\n",
      "Processing 11.tif\n",
      "Processing 12.tif\n",
      "Processing 13.tif\n",
      "Processing 14.tif\n",
      "Processing 15.tif\n",
      "Processing 16.tif\n",
      "Processing 17.tif\n",
      "Processing 18.tif\n",
      "Processing 19.tif\n",
      "Processing 20.tif\n",
      "Processing 21.tif\n",
      "Processing 22.tif\n",
      "Processing 23.tif\n",
      "Processing 24.tif\n",
      "Processing 25.tif\n",
      "Processing 26.tif\n",
      "Processing 27.tif\n",
      "Processing 28.tif\n",
      "Processing 29.tif\n",
      "Processing 30.tif\n",
      "Processing 31.tif\n",
      "Processing 32.tif\n",
      "Processing 33.tif\n",
      "Processing 34.tif\n",
      "Processing 35.tif\n",
      "Processing 36.tif\n",
      "Processing 37.tif\n",
      "Processing 38.tif\n",
      "Processing 39.tif\n",
      "Processing 40.tif\n",
      "Processing 41.tif\n",
      "Processing 42.tif\n",
      "Processing 43.tif\n",
      "Processing 44.tif\n",
      "Processing 45.tif\n",
      "Processing 46.tif\n",
      "Processing 47.tif\n",
      "Processing 48.tif\n",
      "Processing 49.tif\n",
      "Processing 50.tif\n",
      "Processing 51.tif\n",
      "Processing 52.tif\n",
      "Processing 53.tif\n",
      "Processing 54.tif\n",
      "Processing 55.tif\n",
      "Processing 56.tif\n",
      "Processing 57.tif\n",
      "Processing 58.tif\n",
      "Processing 59.tif\n",
      "Processing 60.tif\n",
      "Processing 61.tif\n",
      "Processing 62.tif\n",
      "Processing 63.tif\n",
      "Processing 64.tif\n",
      "Zarr file output.zarr has been created with datasets .volume and .truth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zarr\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# Path to your TIFF files and mask\n",
    "root_dir = \"/home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/1\"\n",
    "tif_folder = f\"{root_dir}/surface_volume\"\n",
    "mask_path = f\"{root_dir}/mask.png\"\n",
    "\n",
    "# Read mask image\n",
    "mask_data = imageio.imread(mask_path)\n",
    "\n",
    "# Initialize the Zarr file\n",
    "zarr_file = \"output.zarr\"\n",
    "root = zarr.open_group(zarr_file, mode='w')\n",
    "\n",
    "# Create 3D Zarr array for volume\n",
    "first_tif = tifffile.imread(os.path.join(tif_folder, \"00.tif\"))\n",
    "z_shape, y_shape, x_shape = len(os.listdir(tif_folder)), first_tif.shape[0], first_tif.shape[1]\n",
    "volume = root.create_dataset(\"volume\", shape=(z_shape, y_shape, x_shape), chunks=(1, y_shape, x_shape), dtype=first_tif.dtype)\n",
    "\n",
    "# Create 2D Zarr array for truth (mask)\n",
    "truth = root.create_dataset(\"truth\", shape=mask_data.shape, chunks=mask_data.shape, dtype=mask_data.dtype)\n",
    "truth[:] = mask_data  # Write mask data to Zarr array\n",
    "\n",
    "# Read each TIFF file and write to Zarr array\n",
    "print(f\"Reading TIFF files\")\n",
    "for i, filename in enumerate(sorted(os.listdir(tif_folder))):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        tif_path = os.path.join(tif_folder, filename)\n",
    "        tif_data = tifffile.imread(tif_path)\n",
    "        \n",
    "        # Make sure to validate the shape and dtype of each TIFF if needed\n",
    "        assert tif_data.shape == (y_shape, x_shape)\n",
    "        assert tif_data.dtype == first_tif.dtype\n",
    "        \n",
    "        # Write the TIFF data to the Zarr array\n",
    "        volume[i, :, :] = tif_data\n",
    "\n",
    "print(f\"Zarr file {zarr_file} has been created with datasets .volume and .truth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.volume[0, 0:10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/viktor/Documents/kaggle/vesuvius-challenge/notebooks/efficient-data-loading.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.13/home/viktor/Documents/kaggle/vesuvius-challenge/notebooks/efficient-data-loading.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m output\u001b[39m.\u001b[39mvolume\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PathNotFoundError",
     "evalue": "nothing found at path ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPathNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/viktor/Documents/kaggle/vesuvius-challenge/notebooks/efficient-data-loading.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.13/home/viktor/Documents/kaggle/vesuvius-challenge/notebooks/efficient-data-loading.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m zarr\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39m/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-1.zarr\u001b[39;49m\u001b[39m\"\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-env/lib/python3.9/site-packages/zarr/convenience.py:122\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(store, mode, zarr_version, path, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m open_group(_store, mode\u001b[39m=\u001b[39mmode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m PathNotFoundError(path)\n",
      "\u001b[0;31mPathNotFoundError\u001b[0m: nothing found at path ''"
     ]
    }
   ],
   "source": [
    "x = zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-1.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import zarr\n",
    "import tifffile\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_zarr_file(folder: str, z_start: int = 0, z_end: int = None) -> zarr.core.Array:\n",
    "    \"\"\"\n",
    "    Create an in-memory Zarr store from a given folder.\n",
    "    zarr .volume is uint16, mask and label are uint8\n",
    "    \"\"\"\n",
    "\n",
    "    # Paths to TIFF, mask, and labels\n",
    "    tif_folder = f\"{folder}/surface_volume\"\n",
    "    mask_path = f\"{folder}/mask.png\"\n",
    "    label_path = f\"{folder}/inklabels.png\" if os.path.exists(f\"{folder}/inklabels.png\") else None\n",
    "\n",
    "    # Read mask and labels\n",
    "    mask_data = imageio.imread(mask_path, pilmode='L')\n",
    "    label_data = imageio.imread(label_path, pilmode='L') if label_path else None\n",
    "\n",
    "\n",
    "    # Initialize in-memory Zarr store\n",
    "    store = zarr.MemoryStore()\n",
    "    root = zarr.group(store=store)\n",
    "\n",
    "    # Create Zarr array for mask\n",
    "    mask_zarr = root.create_dataset(\"mask\", shape=mask_data.shape, chunks=mask_data.shape, dtype=mask_data.dtype)\n",
    "    mask_zarr[:] = mask_data\n",
    "\n",
    "    # Create Zarr array for label if it exists\n",
    "    if label_data is not None:\n",
    "        label_zarr = root.create_dataset(\"label\", shape=label_data.shape, chunks=label_data.shape, dtype=label_data.dtype)\n",
    "        label_zarr[:] = label_data\n",
    "\n",
    "    # Get list of TIFF files and apply slicing\n",
    "    tif_files = sorted([f for f in os.listdir(tif_folder) if f.endswith('.tif')])[z_start:z_end]\n",
    "\n",
    "    # Read first TIFF to determine shape and dtype\n",
    "    first_tif_path = os.path.join(tif_folder, tif_files[0])\n",
    "    first_tif = tifffile.imread(first_tif_path)\n",
    "\n",
    "    # Create 3D Zarr array for volume\n",
    "    z_shape, y_shape, x_shape = len(tif_files), first_tif.shape[0], first_tif.shape[1]\n",
    "    volume = root.create_dataset(\"volume\", shape=(z_shape, y_shape, x_shape), chunks=(1, y_shape, x_shape), dtype=first_tif.dtype)\n",
    "\n",
    "    # Read each TIFF file and write to Zarr array\n",
    "    print(f\"Reading TIFF files from folder {tif_folder}\")\n",
    "    for i, filename in tqdm(enumerate(tif_files), total=z_shape):\n",
    "        tif_path = os.path.join(tif_folder, filename)\n",
    "        tif_data = tifffile.imread(tif_path)\n",
    "\n",
    "        # Make sure to validate the shape and dtype of each TIFF if needed\n",
    "        assert tif_data.shape == (y_shape, x_shape)\n",
    "        assert tif_data.dtype == first_tif.dtype\n",
    "\n",
    "        # Write the TIFF data to the Zarr array\n",
    "        volume[i, :, :] = tif_data\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4055017/1992781192.py:25: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  mask_data = imageio.imread(mask_path, pilmode='L')\n",
      "/tmp/ipykernel_4055017/1992781192.py:26: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  label_data = imageio.imread(label_path, pilmode='L') if label_path else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TIFF files from folder /home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/1/surface_volume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = \"/home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/1\"\n",
    "\n",
    "# Create Zarr store from folder\n",
    "root = get_zarr_file(root_dir, z_start=8, z_end=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8181, 6330)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.label[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "[2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (140973980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TIFF files from folder /home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/2/surface_volume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TIFF files from folder /home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train/3/surface_volume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': (14830, 9506), '3': (7606, 5249)}\n",
      "Fragments shape is {'2': (14830, 9506), '3': (7606, 5249)}\n",
      "Creating train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:21<00:00,  2.66it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 14.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from kaggle_vesuvius.dataloaders import VesuviusDataset\n",
    "\n",
    "train_dataset = VesuviusDataset(mode='train',\n",
    "                                          data_dir='/home/viktor/Documents/kaggle/vesuvius-challenge/data/kaggle-data/train', \n",
    "                                          crop_size=256,\n",
    "                                          eval_on=1,\n",
    "                                          z_start=8,\n",
    "                                          z_end=16,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_vesuvius.losses import get_loss_function\n",
    "\n",
    "loss_configs = [\n",
    "        {\n",
    "            \"name\": \"bce\",\n",
    "            \"params\": {\n",
    "                \"weight\": 0.5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dice\",\n",
    "            \"params\": {\n",
    "                \"weight\": 0.5\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "criterion = get_loss_function(loss_configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
