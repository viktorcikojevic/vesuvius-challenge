{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73dea9ca",
   "metadata": {
    "papermill": {
     "duration": 0.006587,
     "end_time": "2023-04-08T10:11:36.662576",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.655989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vesuvius Challenge - Ink Detection Training Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdbb7ff",
   "metadata": {
    "papermill": {
     "duration": 0.004951,
     "end_time": "2023-04-08T10:11:36.672955",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.668004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae445317",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:43.748797Z",
     "iopub.status.busy": "2023-05-21T21:06:43.748412Z",
     "iopub.status.idle": "2023-05-21T21:06:43.926626Z",
     "shell.execute_reply": "2023-05-21T21:06:43.924859Z"
    },
    "papermill": {
     "duration": 29.297355,
     "end_time": "2023-04-08T10:12:05.976007",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.678652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Pretrained weights\n",
    "# # ref - https://github.com/kenshohara/3D-ResNets-PyTorch\n",
    "# !pip install gdown\n",
    "# !gdown 1Nb4abvIkkp_ydPFA9sNPT1WakoVKA8Fa\n",
    "\n",
    "# # Utility packages for reading and visualizing volumes\n",
    "# !pip install zarr imageio-ffmpeg\n",
    "\n",
    "# save model checkpoints\n",
    "!mkdir ./ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d956f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:43.932131Z",
     "iopub.status.busy": "2023-05-21T21:06:43.931740Z",
     "iopub.status.idle": "2023-05-21T21:06:44.696509Z",
     "shell.execute_reply": "2023-05-21T21:06:44.696015Z"
    },
    "papermill": {
     "duration": 3.289261,
     "end_time": "2023-04-08T10:12:09.273534",
     "exception": false,
     "start_time": "2023-04-08T10:12:05.984273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import zarr\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.append(\"./resnet3d\")\n",
    "from resnet3d import generate_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b00fe4",
   "metadata": {
    "papermill": {
     "duration": 0.007297,
     "end_time": "2023-04-08T10:12:09.288770",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.281473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e26b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.698211Z",
     "iopub.status.busy": "2023-05-21T21:06:44.697988Z",
     "iopub.status.idle": "2023-05-21T21:06:44.700256Z",
     "shell.execute_reply": "2023-05-21T21:06:44.699950Z"
    },
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-04-08T10:12:09.312935",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.296364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "CROP_SIZE = 256\n",
    "Z_START = 24\n",
    "Z_DIMS = 16\n",
    "TRAIN_FRAGMENTS = [\"2\", \"3\"]\n",
    "TEST_FRAGMENT = \"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a1e0328",
   "metadata": {
    "papermill": {
     "duration": 0.007428,
     "end_time": "2023-04-08T10:12:09.328094",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.320666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c494d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.701345Z",
     "iopub.status.busy": "2023-05-21T21:06:44.701232Z",
     "iopub.status.idle": "2023-05-21T21:06:44.709351Z",
     "shell.execute_reply": "2023-05-21T21:06:44.709127Z"
    },
    "papermill": {
     "duration": 0.054715,
     "end_time": "2023-04-08T10:12:09.391635",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.336920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FRAGMENTS_ZARR = {\n",
    "    \"1\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-1.zarr\", mode=\"r\"),\n",
    "    \"2\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-2.zarr\", mode=\"r\"),\n",
    "    \"3\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-3.zarr\", mode=\"r\")\n",
    "}\n",
    "\n",
    "FRAGMENTS_SHAPE = {k : v.mask.shape for k, v in FRAGMENTS_ZARR.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97a51afa",
   "metadata": {
    "papermill": {
     "duration": 0.007406,
     "end_time": "2023-04-08T10:12:09.406465",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.399059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualise input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33b9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.710520Z",
     "iopub.status.busy": "2023-05-21T21:06:44.710365Z",
     "iopub.status.idle": "2023-05-21T21:06:44.861014Z",
     "shell.execute_reply": "2023-05-21T21:06:44.860712Z"
    },
    "papermill": {
     "duration": 1.68744,
     "end_time": "2023-04-08T10:12:11.101290",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.413850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragment = FRAGMENTS_ZARR[\"1\"]\n",
    "x, y = 2000, 2000\n",
    "\n",
    "fragment_cropped = fragment.surface_volume[y:y+CROP_SIZE, x:x+CROP_SIZE, Z_START:Z_START+Z_DIMS]\n",
    "imageio.mimwrite(\"fragment_crop.mp4\", fragment_cropped.transpose(2, 0, 1), \"ffmpeg\")\n",
    "Video(\"fragment_crop.mp4\", height=256, width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46203a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.862241Z",
     "iopub.status.busy": "2023-05-21T21:06:44.862111Z",
     "iopub.status.idle": "2023-05-21T21:06:44.901721Z",
     "shell.execute_reply": "2023-05-21T21:06:44.901517Z"
    },
    "papermill": {
     "duration": 0.258785,
     "end_time": "2023-04-08T10:12:11.368608",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.109823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_cropped = fragment.truth[y:y+CROP_SIZE, x:x+CROP_SIZE]\n",
    "ir_cropped = fragment.infrared[y:y+CROP_SIZE, x:x+CROP_SIZE]\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mask_cropped, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(ir_cropped, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462d25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.902743Z",
     "iopub.status.busy": "2023-05-21T21:06:44.902635Z",
     "iopub.status.idle": "2023-05-21T21:06:44.950370Z",
     "shell.execute_reply": "2023-05-21T21:06:44.950169Z"
    },
    "papermill": {
     "duration": 0.17287,
     "end_time": "2023-04-08T10:12:11.562933",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.390063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del fragment, fragment_cropped, mask_cropped, ir_cropped\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff9cd3e8",
   "metadata": {
    "papermill": {
     "duration": 0.008474,
     "end_time": "2023-04-08T10:12:11.580070",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.571596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ec4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.951633Z",
     "iopub.status.busy": "2023-05-21T21:06:44.951543Z",
     "iopub.status.idle": "2023-05-21T21:06:44.953404Z",
     "shell.execute_reply": "2023-05-21T21:06:44.953225Z"
    },
    "papermill": {
     "duration": 0.024571,
     "end_time": "2023-04-08T10:12:11.612905",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.588334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# class VesuviusTrain(Dataset):\n",
    "#     def __init__(self, fragments):\n",
    "#         self.fragments = fragments\n",
    "#         self.xys = []\n",
    "        \n",
    "#         for fragment in fragments:\n",
    "#             H, W = FRAGMENTS_SHAPE[fragment]\n",
    "#             for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "#                 for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "#                     self.xys.append((fragment, x, y, W, H))\n",
    "        \n",
    "#         train_aug_list = [\n",
    "#                 # A.RandomResizedCrop(\n",
    "#                 #     size, size, scale=(0.85, 1.0)),\n",
    "#                 A.HorizontalFlip(p=0.5),\n",
    "#                 A.VerticalFlip(p=0.5),\n",
    "#                 A.RandomBrightnessContrast(p=0.75),\n",
    "#                 A.CoarseDropout(max_holes=1, max_width=int(CROP_SIZE * 0.1), max_height=int(size * 0.1), \n",
    "#                                 mask_fill_value=0, p=0.5),\n",
    "#                 A.ShiftScaleRotate(p=0.75),\n",
    "#                 A.Rotate(limit=90, p=0.9), \n",
    "#                 A.OneOf([\n",
    "#                         A.GaussNoise(var_limit=[10, 50]),\n",
    "#                         A.GaussianBlur(),\n",
    "#                         A.MotionBlur(),\n",
    "#                         ], p=0.4),\n",
    "#                 A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "                \n",
    "#                 A.Cutout(max_h_size=int(size * 0.6),\n",
    "#                          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "#                 A.Normalize(\n",
    "#                     mean= [0] * Z_DIMS,\n",
    "#                     std= [1] * Z_DIMS\n",
    "#                 ),\n",
    "#                 ToTensorV2(transpose_mask=True),\n",
    "#             ]\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def __getitem__(self, i):\n",
    "#         fragment, x1, y1, W, H = self.xys[i]\n",
    "#         z1, z2 = Z_START, Z_START+Z_DIMS\n",
    "        \n",
    "#         x_offset = random.randint(-32 if x1 != 0 else 0, 32)\n",
    "#         y_offset = random.randint(-32 if y1 != 0 else 0, 32)\n",
    "        \n",
    "#         x1 += x_offset\n",
    "#         y1 += y_offset\n",
    "        \n",
    "#         x2 = x1 + CROP_SIZE\n",
    "#         y2 = y1 + CROP_SIZE\n",
    "        \n",
    "#         if x2 > W:\n",
    "#             x1 -= x_offset\n",
    "#             x2 -= x_offset\n",
    "            \n",
    "#         if y2 > H:\n",
    "#             y1 -= y_offset\n",
    "#             y2 -= y_offset\n",
    "        \n",
    "#         frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, z1:z2]\n",
    "#         mask_crop = FRAGMENTS_ZARR[fragment].truth[y1:y2, x1:x2]\n",
    "        \n",
    "#         if random.random() > 0.5:\n",
    "#             frag_crop = np.flip(frag_crop, axis=1).copy()\n",
    "#             mask_crop = np.flip(mask_crop, axis=1).copy()\n",
    "\n",
    "#         frag_crop = torch.from_numpy(frag_crop.astype(np.float32)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "#         frag_crop = frag_crop/65535.0\n",
    "#         frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "#         mask_crop = torch.from_numpy(mask_crop.astype(np.float32)).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         return frag_crop, mask_crop\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0c6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:44.954560Z",
     "iopub.status.busy": "2023-05-21T21:06:44.954480Z",
     "iopub.status.idle": "2023-05-21T21:06:45.285554Z",
     "shell.execute_reply": "2023-05-21T21:06:45.285298Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class VesuviusTrain(Dataset):\n",
    "    def __init__(self, fragments):\n",
    "        self.fragments = fragments\n",
    "        self.xys = []\n",
    "        \n",
    "        for fragment in fragments:\n",
    "            H, W = FRAGMENTS_SHAPE[fragment]\n",
    "            for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "                for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "                    surface = FRAGMENTS_ZARR[fragment].surface_volume[y:y+CROP_SIZE, x:x+CROP_SIZE, 0]\n",
    "                    if np.sum(surface) / (CROP_SIZE * CROP_SIZE) > 0.2:\n",
    "                        self.xys.append((fragment, x, y, W, H))\n",
    "        \n",
    "        self.train_aug_list = [\n",
    "                # A.RandomResizedCrop(\n",
    "                #     size, size, scale=(0.85, 1.0)),\n",
    "                \n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                \n",
    "                # A.RandomBrightnessContrast(p=0.75),\n",
    "                # A.CoarseDropout(max_holes=1, max_width=int(CROP_SIZE * 0.1), max_height=int(CROP_SIZE * 0.1), \n",
    "                #                 mask_fill_value=0, p=0.5),\n",
    "                # A.ShiftScaleRotate(p=0.75),\n",
    "                \n",
    "                A.Rotate(limit=90, p=0.9), \n",
    "                \n",
    "                # A.OneOf([\n",
    "                #         A.GaussNoise(var_limit=[1, 5]),\n",
    "                #         A.GaussianBlur(),\n",
    "                #         A.MotionBlur(),\n",
    "                #         ], p=0.4),\n",
    "                # A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "                \n",
    "                # A.Cutout(max_h_size=int(CROP_SIZE * 0.2),\n",
    "                #          max_w_size=int(CROP_SIZE * 0.2), num_holes=1, p=1.0),\n",
    "                # A.Normalize(\n",
    "                #     mean= [0] * Z_DIMS,\n",
    "                #     std= [1] * Z_DIMS\n",
    "                # ),\n",
    "                \n",
    "                \n",
    "                ToTensorV2(transpose_mask=True),\n",
    "            ]\n",
    "        \n",
    "        # Create the augmentation pipeline\n",
    "        self.augmentations = A.Compose(self.train_aug_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        fragment, x1, y1, W, H = self.xys[i]\n",
    "        z1, z2 = Z_START, Z_START+Z_DIMS\n",
    "        \n",
    "        x_offset = random.randint(-128 if x1 != 0 else 0, 128)\n",
    "        y_offset = random.randint(-128 if y1 != 0 else 0, 128)\n",
    "        \n",
    "        x1 += x_offset\n",
    "        y1 += y_offset\n",
    "        \n",
    "        x2 = x1 + CROP_SIZE\n",
    "        y2 = y1 + CROP_SIZE\n",
    "        \n",
    "        if x2 > W:\n",
    "            x1 -= x_offset\n",
    "            x2 -= x_offset\n",
    "            \n",
    "        if y2 > H:\n",
    "            y1 -= y_offset\n",
    "            y2 -= y_offset\n",
    "        \n",
    "        frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, z1:z2]\n",
    "        mask_crop = FRAGMENTS_ZARR[fragment].truth[y1:y2, x1:x2]\n",
    "        \n",
    "        # if random.random() > 0.5:\n",
    "        #     frag_crop = np.flip(frag_crop, axis=1).copy()\n",
    "        #     mask_crop = np.flip(mask_crop, axis=1).copy()\n",
    "\n",
    "        # Perform train augmentations\n",
    "\n",
    "        frag_crop = frag_crop/65535.0\n",
    "        \n",
    "\n",
    "        # Apply the augmentations\n",
    "        augmented = self.augmentations(image=frag_crop, mask=mask_crop)\n",
    "\n",
    "        # Separate the image and mask\n",
    "        frag_crop, mask_crop = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        # normalize\n",
    "        \n",
    "        # frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "        frag_crop = frag_crop.unsqueeze(0)\n",
    "        mask_crop = mask_crop.float().unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        return frag_crop, mask_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172c2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:45.287050Z",
     "iopub.status.busy": "2023-05-21T21:06:45.286845Z",
     "iopub.status.idle": "2023-05-21T21:06:45.290230Z",
     "shell.execute_reply": "2023-05-21T21:06:45.289946Z"
    },
    "papermill": {
     "duration": 0.022963,
     "end_time": "2023-04-08T10:12:11.644387",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.621424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VesuviusVal(Dataset):\n",
    "    def __init__(self, fragment):\n",
    "        self.fragment = FRAGMENTS_ZARR[fragment]\n",
    "        self.xys = []\n",
    "        \n",
    "        H, W = FRAGMENTS_SHAPE[fragment]\n",
    "        for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "            for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "                self.xys.append((x, y))\n",
    "                \n",
    "    def __getitem__(self, i):\n",
    "        x1, y1 = self.xys[i]\n",
    "        x2, y2 = x1+CROP_SIZE, y1+CROP_SIZE\n",
    "        z1, z2 = Z_START, Z_START+Z_DIMS\n",
    "        \n",
    "        frag_crop = self.fragment.surface_volume[y1:y2, x1:x2, z1:z2]\n",
    "        mask_crop = self.fragment.truth[y1:y2, x1:x2]\n",
    "\n",
    "        frag_crop = torch.from_numpy(frag_crop.astype(np.float32)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        frag_crop = frag_crop/65535.0\n",
    "        # frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "        mask_crop = torch.from_numpy(mask_crop.astype(np.float32)).unsqueeze(0)\n",
    "        return frag_crop, mask_crop, torch.tensor([x1, y1, x2, y2], dtype=torch.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282f924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:45.291208Z",
     "iopub.status.busy": "2023-05-21T21:06:45.291125Z",
     "iopub.status.idle": "2023-05-21T21:06:50.760696Z",
     "shell.execute_reply": "2023-05-21T21:06:50.760450Z"
    },
    "papermill": {
     "duration": 0.019671,
     "end_time": "2023-04-08T10:12:11.672490",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.652819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = VesuviusTrain(TRAIN_FRAGMENTS)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=2,\n",
    "                              shuffle=True, pin_memory=True, drop_last=True)\n",
    "n_train = len(dataloader_train)\n",
    "\n",
    "dataset_valid = VesuviusVal(TEST_FRAGMENT)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=2,\n",
    "                              shuffle=False, pin_memory=True, drop_last=False)\n",
    "n_valid = len(dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577f1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:50.761964Z",
     "iopub.status.busy": "2023-05-21T21:06:50.761851Z",
     "iopub.status.idle": "2023-05-21T21:06:50.780861Z",
     "shell.execute_reply": "2023-05-21T21:06:50.780609Z"
    }
   },
   "outputs": [],
   "source": [
    "i = random.randint(0, len(dataset_train))\n",
    "img = dataset_train[i][0]\n",
    "img.min(), img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a15748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792af0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdcc7e0b",
   "metadata": {
    "papermill": {
     "duration": 0.008028,
     "end_time": "2023-04-08T10:12:11.688860",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.680832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model\n",
    "* Encoder is a 3D ResNet model. The architecture has been modified to remove temporal downsampling between blocks.\n",
    "* A 2D decoder is used for predicting the segmentation map.\n",
    "* The encoder feature maps are average pooled over the Z dimension before passing it to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cc8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:50.782116Z",
     "iopub.status.busy": "2023-05-21T21:06:50.781997Z",
     "iopub.status.idle": "2023-05-21T21:06:50.786174Z",
     "shell.execute_reply": "2023-05-21T21:06:50.785934Z"
    },
    "papermill": {
     "duration": 0.023714,
     "end_time": "2023-04-08T10:12:11.721140",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.697426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder_dims, upscale):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(encoder_dims[i]+encoder_dims[i-1], encoder_dims[i-1], 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(encoder_dims[i-1]),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for i in range(1, len(encoder_dims))])\n",
    "\n",
    "        self.logit = nn.Conv2d(encoder_dims[0], 1, 1, 1, 0)\n",
    "        self.up = nn.Upsample(scale_factor=upscale, mode=\"bilinear\")\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        for i in range(len(feature_maps)-1, 0, -1):\n",
    "            f_up = F.interpolate(feature_maps[i], scale_factor=2, mode=\"bilinear\")\n",
    "            f = torch.cat([feature_maps[i-1], f_up], dim=1)\n",
    "            f_down = self.convs[i-1](f)\n",
    "            feature_maps[i-1] = f_down\n",
    "\n",
    "        x = self.logit(feature_maps[0])\n",
    "        mask = self.up(x)\n",
    "        return mask\n",
    "\n",
    "\n",
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = generate_model(model_depth=18, n_input_channels=1)\n",
    "        self.decoder = Decoder(encoder_dims=[64, 128, 256, 512], upscale=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat_maps = self.encoder(x)\n",
    "        feat_maps_pooled = [torch.mean(f, dim=2) for f in feat_maps]\n",
    "        pred_mask = self.decoder(feat_maps_pooled)\n",
    "        return pred_mask\n",
    "    \n",
    "    def load_pretrained_weights(self, state_dict):\n",
    "        # Convert 3 channel weights to single channel\n",
    "        # ref - https://timm.fast.ai/models#Case-1:-When-the-number-of-input-channels-is-1\n",
    "        conv1_weight = state_dict['conv1.weight']\n",
    "        state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "        print(self.encoder.load_state_dict(state_dict, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4a0f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:50.787509Z",
     "iopub.status.busy": "2023-05-21T21:06:50.787312Z",
     "iopub.status.idle": "2023-05-21T21:06:51.679886Z",
     "shell.execute_reply": "2023-05-21T21:06:51.679541Z"
    },
    "papermill": {
     "duration": 3.891528,
     "end_time": "2023-04-08T10:12:15.621016",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.729488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SegModel()\n",
    "model.load_pretrained_weights(torch.load(\"/home/viktor/Documents/kaggle/vesuvius-challenge/experiments/3D-resnet/r3d18_K_200ep.pth\")[\"state_dict\"])\n",
    "model = nn.DataParallel(model, device_ids=[0])\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e9288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:51.681557Z",
     "iopub.status.busy": "2023-05-21T21:06:51.681416Z",
     "iopub.status.idle": "2023-05-21T21:06:52.520403Z",
     "shell.execute_reply": "2023-05-21T21:06:52.519941Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5, 1, 16, 256, 256).cuda()\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d84d7c0e",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2023-04-08T10:12:15.638951",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.630135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Competition metric (F0.5 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbeb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:52.521833Z",
     "iopub.status.busy": "2023-05-21T21:06:52.521732Z",
     "iopub.status.idle": "2023-05-21T21:06:52.524000Z",
     "shell.execute_reply": "2023-05-21T21:06:52.523811Z"
    },
    "papermill": {
     "duration": 0.020268,
     "end_time": "2023-04-08T10:12:15.668008",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.647740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "def fbeta_score(preds, targets, threshold, beta=0.5, smooth=1e-5):\n",
    "    preds_t = torch.where(preds > threshold, 1.0, 0.0).float()\n",
    "    y_true_count = targets.sum()\n",
    "    \n",
    "    ctp = preds_t[targets==1].sum()\n",
    "    cfp = preds_t[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "639c9148",
   "metadata": {
    "papermill": {
     "duration": 0.008498,
     "end_time": "2023-04-08T10:12:15.685205",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.676707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca2e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:52.525249Z",
     "iopub.status.busy": "2023-05-21T21:06:52.525169Z",
     "iopub.status.idle": "2023-05-21T21:06:52.527275Z",
     "shell.execute_reply": "2023-05-21T21:06:52.527093Z"
    },
    "papermill": {
     "duration": 0.019067,
     "end_time": "2023-04-08T10:12:15.713237",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.694170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
    "                                                steps_per_epoch=10, epochs=EPOCHS//10,\n",
    "                                                pct_start=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "DiceLoss = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304e1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:52.528502Z",
     "iopub.status.busy": "2023-05-21T21:06:52.528351Z",
     "iopub.status.idle": "2023-05-21T21:06:52.564140Z",
     "shell.execute_reply": "2023-05-21T21:06:52.563789Z"
    },
    "papermill": {
     "duration": 0.385175,
     "end_time": "2023-04-08T10:12:16.107159",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.721984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_mask = torch.from_numpy(np.asarray(FRAGMENTS_ZARR[TEST_FRAGMENT].truth)).float().cuda()\n",
    "gt_shape = FRAGMENTS_SHAPE[TEST_FRAGMENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b85bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:52.565720Z",
     "iopub.status.busy": "2023-05-21T21:06:52.565618Z",
     "iopub.status.idle": "2023-05-21T21:06:52.567491Z",
     "shell.execute_reply": "2023-05-21T21:06:52.567294Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"training_log.txt\", level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00067c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:06:52.568757Z",
     "iopub.status.busy": "2023-05-21T21:06:52.568669Z",
     "iopub.status.idle": "2023-05-21T21:28:13.958578Z",
     "shell.execute_reply": "2023-05-21T21:28:13.958219Z"
    },
    "papermill": {
     "duration": 4077.588277,
     "end_time": "2023-04-08T11:20:13.706513",
     "exception": false,
     "start_time": "2023-04-08T10:12:16.118236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fbeta_best = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    cur_lr = f\"LR : {scheduler.get_last_lr()[0]:.2E}\"\n",
    "    pbar_train = enumerate(dataloader_train)\n",
    "    pbar_train = tqdm(pbar_train, total=n_train, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    mloss_train, mloss_val, val_metric = 0.0, 0.0, 0.0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i, (fragments, masks) in pbar_train:\n",
    "        fragments, masks = fragments.cuda().half(), masks.cuda().half()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast():\n",
    "            pred_masks = model(fragments)\n",
    "            loss = criterion(pred_masks, masks)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            mloss_train += loss.detach().item()\n",
    "\n",
    "        gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
    "        pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{EPOCHS}\", gpu_mem, cur_lr,\n",
    "                                                              f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
    "        \n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    pbar_val = enumerate(dataloader_valid)\n",
    "    pbar_val = tqdm(pbar_val, total=n_valid, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    final_pred_mask = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    for i, (fragments, masks, xys) in pbar_val:\n",
    "        fragments, masks = fragments.cuda(), masks.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_masks = model(fragments)\n",
    "            mloss_val += criterion(pred_masks, masks).item()\n",
    "            pred_masks = torch.sigmoid(pred_masks)\n",
    "        \n",
    "        for j, xy in enumerate(xys):\n",
    "            final_pred_mask[xy[1]:xy[3], xy[0]:xy[2]] = pred_masks[j, 0]\n",
    "\n",
    "        pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
    "    \n",
    "    for threshold in np.arange(0.2, 0.85, 0.05):\n",
    "        fbeta = fbeta_score(final_pred_mask, gt_mask, threshold)\n",
    "        print(f\"Threshold : {threshold:.2f}\\tFBeta : {fbeta:.6f}\")\n",
    "        \n",
    "        if fbeta_best < fbeta:\n",
    "            fbeta_best = fbeta\n",
    "            torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_best_{fbeta_best:.4f}.pt\")\n",
    "    \n",
    "    \n",
    "    if epoch >= 10:\n",
    "        torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_epoch_{epoch}.pt\")\n",
    "\n",
    "    # if epoch == 30:\n",
    "    #     break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48f344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T21:28:13.960107Z",
     "iopub.status.busy": "2023-05-21T21:28:13.959966Z",
     "iopub.status.idle": "2023-05-21T21:28:13.962033Z",
     "shell.execute_reply": "2023-05-21T21:28:13.961850Z"
    }
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# logging.basicConfig(filename=\"training_log.txt\", level=logging.INFO)\n",
    "\n",
    "# console = logging.StreamHandler()\n",
    "# console.setLevel(logging.INFO)\n",
    "# logging.getLogger('').addHandler(console)\n",
    "\n",
    "# fbeta_best = 0.0\n",
    "# for epoch in range(1, EPOCHS+1):\n",
    "#     model.train()\n",
    "#     cur_lr = f\"LR : {scheduler.get_last_lr()[0]:.2E}\"\n",
    "#     pbar_train = enumerate(dataloader_train)\n",
    "#     pbar_train = tqdm(pbar_train, total=n_train, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "#     mloss_train, mloss_val, val_metric = 0.0, 0.0, 0.0\n",
    "\n",
    "#     for i, (fragments, masks) in pbar_train:\n",
    "#         fragments, masks = fragments.cuda().half(), masks.cuda().half()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         with amp.autocast():\n",
    "#             pred_masks = model(fragments)\n",
    "#             loss = criterion(pred_masks, masks)\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#             mloss_train += loss.detach().item()\n",
    "\n",
    "#         gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
    "#         pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{EPOCHS}\", gpu_mem, cur_lr,\n",
    "#                                                               f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
    "#         logging.info((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{EPOCHS}\", gpu_mem, cur_lr,\n",
    "#                                                 f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
    "#     scheduler.step()\n",
    "#     model.eval()\n",
    "#     pbar_val = enumerate(dataloader_valid)\n",
    "#     pbar_val = tqdm(pbar_val, total=n_valid, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "#     final_pred_mask = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n",
    "    \n",
    "#     for i, (fragments, masks, xys) in pbar_val:\n",
    "#         fragments, masks = fragments.cuda(), masks.cuda()\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             pred_masks = model(fragments)\n",
    "#             mloss_val += criterion(pred_masks, masks).item()\n",
    "#             pred_masks = torch.sigmoid(pred_masks)\n",
    "        \n",
    "#         for j, xy in enumerate(xys):\n",
    "#             final_pred_mask[xy[1]:xy[3], xy[0]:xy[2]] = pred_masks[j, 0]\n",
    "\n",
    "#         pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
    "#         logging.info((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
    "\n",
    "#     for threshold in np.arange(0.2, 0.85, 0.05):\n",
    "#         fbeta = fbeta_score(final_pred_mask, gt_mask, threshold)\n",
    "#         logging.info(f\"Threshold : {threshold:.2f}\\tFBeta : {fbeta:.6f}\")\n",
    "\n",
    "#         if fbeta_best < fbeta:\n",
    "#             fbeta_best = fbeta\n",
    "#             torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_best.pt\")\n",
    "    \n",
    "#     # if epoch >= 10:\n",
    "#     #     torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_epoch_{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89431087",
   "metadata": {
    "papermill": {
     "duration": 0.381515,
     "end_time": "2023-04-08T11:20:14.478012",
     "exception": false,
     "start_time": "2023-04-08T11:20:14.096497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4132.646938,
   "end_time": "2023-04-08T11:20:18.816611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-08T10:11:26.169673",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
