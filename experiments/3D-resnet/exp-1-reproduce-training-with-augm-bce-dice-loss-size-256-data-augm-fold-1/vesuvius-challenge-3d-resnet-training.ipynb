{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73dea9ca",
   "metadata": {
    "papermill": {
     "duration": 0.006587,
     "end_time": "2023-04-08T10:11:36.662576",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.655989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vesuvius Challenge - Ink Detection Training Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdbb7ff",
   "metadata": {
    "papermill": {
     "duration": 0.004951,
     "end_time": "2023-04-08T10:11:36.672955",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.668004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae445317",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:13.260351Z",
     "iopub.status.busy": "2023-05-22T15:19:13.259976Z",
     "iopub.status.idle": "2023-05-22T15:19:13.441616Z",
     "shell.execute_reply": "2023-05-22T15:19:13.439804Z"
    },
    "papermill": {
     "duration": 29.297355,
     "end_time": "2023-04-08T10:12:05.976007",
     "exception": false,
     "start_time": "2023-04-08T10:11:36.678652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Pretrained weights\n",
    "# # ref - https://github.com/kenshohara/3D-ResNets-PyTorch\n",
    "# !pip install gdown\n",
    "# !gdown 1Nb4abvIkkp_ydPFA9sNPT1WakoVKA8Fa\n",
    "\n",
    "# # Utility packages for reading and visualizing volumes\n",
    "# !pip install zarr imageio-ffmpeg\n",
    "\n",
    "# save model checkpoints\n",
    "!mkdir ./ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d956f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:13.447137Z",
     "iopub.status.busy": "2023-05-22T15:19:13.446755Z",
     "iopub.status.idle": "2023-05-22T15:19:14.221250Z",
     "shell.execute_reply": "2023-05-22T15:19:14.220927Z"
    },
    "papermill": {
     "duration": 3.289261,
     "end_time": "2023-04-08T10:12:09.273534",
     "exception": false,
     "start_time": "2023-04-08T10:12:05.984273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import zarr\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.append(\"./resnet3d\")\n",
    "from resnet3d import generate_model\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b00fe4",
   "metadata": {
    "papermill": {
     "duration": 0.007297,
     "end_time": "2023-04-08T10:12:09.288770",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.281473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e26b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.222919Z",
     "iopub.status.busy": "2023-05-22T15:19:14.222729Z",
     "iopub.status.idle": "2023-05-22T15:19:14.224625Z",
     "shell.execute_reply": "2023-05-22T15:19:14.224447Z"
    },
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-04-08T10:12:09.312935",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.296364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 5e-5\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "CROP_SIZE = 256 # 1024+256=1280\n",
    "IMAGE_SIZE = 256\n",
    "Z_DIMS = 24\n",
    "TRAIN_FRAGMENTS = [\"2\", \"3\"]\n",
    "TEST_FRAGMENT = \"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a1e0328",
   "metadata": {
    "papermill": {
     "duration": 0.007428,
     "end_time": "2023-04-08T10:12:09.328094",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.320666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c494d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.225853Z",
     "iopub.status.busy": "2023-05-22T15:19:14.225701Z",
     "iopub.status.idle": "2023-05-22T15:19:14.233668Z",
     "shell.execute_reply": "2023-05-22T15:19:14.233487Z"
    },
    "papermill": {
     "duration": 0.054715,
     "end_time": "2023-04-08T10:12:09.391635",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.336920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FRAGMENTS_ZARR = {\n",
    "    \"1\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-1.zarr\", mode=\"r\"),\n",
    "    \"2\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-2.zarr\", mode=\"r\"),\n",
    "    \"3\" : zarr.open(\"/home/viktor/Documents/kaggle/vesuvius-challenge/kaggle-data/train-3.zarr\", mode=\"r\")\n",
    "}\n",
    "\n",
    "FRAGMENTS_SHAPE = {k : v.mask.shape for k, v in FRAGMENTS_ZARR.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97a51afa",
   "metadata": {
    "papermill": {
     "duration": 0.007406,
     "end_time": "2023-04-08T10:12:09.406465",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.399059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualise input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33b9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.234929Z",
     "iopub.status.busy": "2023-05-22T15:19:14.234816Z",
     "iopub.status.idle": "2023-05-22T15:19:14.433259Z",
     "shell.execute_reply": "2023-05-22T15:19:14.432938Z"
    },
    "papermill": {
     "duration": 1.68744,
     "end_time": "2023-04-08T10:12:11.101290",
     "exception": false,
     "start_time": "2023-04-08T10:12:09.413850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragment = FRAGMENTS_ZARR[\"1\"]\n",
    "x, y = 2000, 2000\n",
    "\n",
    "\n",
    "# take random Z_DIMS integers between 0 and Z_END, without repeating\n",
    "# z = np.random.choice(np.arange(Z_END), Z_DIMS, replace=False)\n",
    "# fragment_cropped = fragment.surface_volume[y:y+CROP_SIZE, x:x+CROP_SIZE, z]\n",
    "# imageio.mimwrite(\"fragment_crop.mp4\", fragment_cropped.transpose(2, 0, 1), \"ffmpeg\")\n",
    "# Video(\"fragment_crop.mp4\", height=256, width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46203a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.434396Z",
     "iopub.status.busy": "2023-05-22T15:19:14.434304Z",
     "iopub.status.idle": "2023-05-22T15:19:14.479072Z",
     "shell.execute_reply": "2023-05-22T15:19:14.478882Z"
    },
    "papermill": {
     "duration": 0.258785,
     "end_time": "2023-04-08T10:12:11.368608",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.109823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_cropped = fragment.truth[y:y+CROP_SIZE, x:x+CROP_SIZE]\n",
    "ir_cropped = fragment.infrared[y:y+CROP_SIZE, x:x+CROP_SIZE]\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mask_cropped, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(ir_cropped, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augm_list = [\n",
    "        #     A.RandomSizedCrop(min_max_height=(1024, CROP_SIZE), height=CROP_SIZE, width=CROP_SIZE, always_apply=True),\n",
    "        #     A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "            # A.RandomScale(scale_limit=0.15, p=0.5),\n",
    "            \n",
    "            \n",
    "            \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "        #     A.Cutout(max_h_size=int(IMAGE_SIZE * 0.02),\n",
    "        #              max_w_size=int(IMAGE_SIZE * 0.02), num_holes=4, p=0.9),\n",
    "        #     A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "        #     A.Cutout(max_h_size=int(IMAGE_SIZE * 0.05),\n",
    "        #              max_w_size=int(IMAGE_SIZE * 0.05), num_holes=4, p=0.7),\n",
    "            A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "        #     A.Cutout(max_h_size=int(IMAGE_SIZE * 0.1),\n",
    "        #              max_w_size=int(IMAGE_SIZE * 0.1), num_holes=4, p=0.7),\n",
    "            \n",
    "        #     A.Cutout(max_h_size=int(IMAGE_SIZE * 0.15),\n",
    "        #              max_w_size=int(IMAGE_SIZE * 0.15), num_holes=2, p=0.7),\n",
    "        #     A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "        #     A.OneOf([\n",
    "        #             A.GaussNoise(var_limit=[0.02, 0.1]),\n",
    "        #             A.GaussianBlur(),\n",
    "        #             A.MotionBlur(),\n",
    "        #             ], p=0.4),\n",
    "            \n",
    "        #     A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "        #     A.Transpose(p=0.5),\n",
    "        #     A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        #     A.RandomContrast(p=0.5),\n",
    "        #     A.RandomGamma(p=0.5)\n",
    "            \n",
    "            \n",
    "            ]\n",
    "\n",
    "# Create the augmentation pipeline\n",
    "augmentations = A.Compose(augm_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e71fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Apply the augmentations\n",
    "augmented = augmentations(image=ir_cropped, mask=mask_cropped)\n",
    "\n",
    "# Separate the image and mask\n",
    "frag_crop, mask_crop = augmented[\"image\"], augmented[\"mask\"]\n",
    "# frag_crop, mask_crop = ir_cropped, mask_cropped\n",
    "\n",
    "print(np.max(ir_cropped), np.max(frag_crop), frag_crop.shape, mask_crop.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(frag_crop, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_crop, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60250cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462d25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.480162Z",
     "iopub.status.busy": "2023-05-22T15:19:14.480077Z",
     "iopub.status.idle": "2023-05-22T15:19:14.526424Z",
     "shell.execute_reply": "2023-05-22T15:19:14.526220Z"
    },
    "papermill": {
     "duration": 0.17287,
     "end_time": "2023-04-08T10:12:11.562933",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.390063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del fragment, fragment_cropped, mask_cropped, ir_cropped\n",
    "# gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff9cd3e8",
   "metadata": {
    "papermill": {
     "duration": 0.008474,
     "end_time": "2023-04-08T10:12:11.580070",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.571596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ec4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.527699Z",
     "iopub.status.busy": "2023-05-22T15:19:14.527603Z",
     "iopub.status.idle": "2023-05-22T15:19:14.529480Z",
     "shell.execute_reply": "2023-05-22T15:19:14.529287Z"
    },
    "papermill": {
     "duration": 0.024571,
     "end_time": "2023-04-08T10:12:11.612905",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.588334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# class VesuviusTrain(Dataset):\n",
    "#     def __init__(self, fragments):\n",
    "#         self.fragments = fragments\n",
    "#         self.xys = []\n",
    "        \n",
    "#         for fragment in fragments:\n",
    "#             H, W = FRAGMENTS_SHAPE[fragment]\n",
    "#             for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "#                 for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "#                     self.xys.append((fragment, x, y, W, H))\n",
    "        \n",
    "#         train_aug_list = [\n",
    "#                 # A.RandomResizedCrop(\n",
    "#                 #     size, size, scale=(0.85, 1.0)),\n",
    "#                 A.HorizontalFlip(p=0.5),\n",
    "#                 A.VerticalFlip(p=0.5),\n",
    "#                 A.RandomBrightnessContrast(p=0.75),\n",
    "#                 A.CoarseDropout(max_holes=1, max_width=int(CROP_SIZE * 0.1), max_height=int(size * 0.1), \n",
    "#                                 mask_fill_value=0, p=0.5),\n",
    "#                 A.ShiftScaleRotate(p=0.75),\n",
    "#                 A.Rotate(limit=90, p=0.9), \n",
    "#                 A.OneOf([\n",
    "#                         A.GaussNoise(var_limit=[10, 50]),\n",
    "#                         A.GaussianBlur(),\n",
    "#                         A.MotionBlur(),\n",
    "#                         ], p=0.4),\n",
    "#                 A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "                \n",
    "#                 A.Cutout(max_h_size=int(size * 0.6),\n",
    "#                          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "#                 A.Normalize(\n",
    "#                     mean= [0] * Z_DIMS,\n",
    "#                     std= [1] * Z_DIMS\n",
    "#                 ),\n",
    "#                 ToTensorV2(transpose_mask=True),\n",
    "#             ]\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def __getitem__(self, i):\n",
    "#         fragment, x1, y1, W, H = self.xys[i]\n",
    "#         z1, z2 = Z_START, Z_START+Z_DIMS\n",
    "        \n",
    "#         x_offset = random.randint(-32 if x1 != 0 else 0, 32)\n",
    "#         y_offset = random.randint(-32 if y1 != 0 else 0, 32)\n",
    "        \n",
    "#         x1 += x_offset\n",
    "#         y1 += y_offset\n",
    "        \n",
    "#         x2 = x1 + CROP_SIZE\n",
    "#         y2 = y1 + CROP_SIZE\n",
    "        \n",
    "#         if x2 > W:\n",
    "#             x1 -= x_offset\n",
    "#             x2 -= x_offset\n",
    "            \n",
    "#         if y2 > H:\n",
    "#             y1 -= y_offset\n",
    "#             y2 -= y_offset\n",
    "        \n",
    "#         frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, z1:z2]\n",
    "#         mask_crop = FRAGMENTS_ZARR[fragment].truth[y1:y2, x1:x2]\n",
    "        \n",
    "#         if random.random() > 0.5:\n",
    "#             frag_crop = np.flip(frag_crop, axis=1).copy()\n",
    "#             mask_crop = np.flip(mask_crop, axis=1).copy()\n",
    "\n",
    "#         frag_crop = torch.from_numpy(frag_crop.astype(np.float32)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "#         frag_crop = frag_crop/65535.0\n",
    "#         frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "#         mask_crop = torch.from_numpy(mask_crop.astype(np.float32)).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         return frag_crop, mask_crop\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0c6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.530581Z",
     "iopub.status.busy": "2023-05-22T15:19:14.530464Z",
     "iopub.status.idle": "2023-05-22T15:19:14.829198Z",
     "shell.execute_reply": "2023-05-22T15:19:14.828882Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class VesuviusTrain(Dataset):\n",
    "    def __init__(self, fragments):\n",
    "        self.fragments = fragments\n",
    "        self.xys = []\n",
    "        \n",
    "        for fragment in fragments:\n",
    "            H, W = FRAGMENTS_SHAPE[fragment]\n",
    "            for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "                for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "                    surface = FRAGMENTS_ZARR[fragment].surface_volume[y:y+CROP_SIZE, x:x+CROP_SIZE, 0]\n",
    "                    if np.sum(surface>0.001) / (surface.shape[0] * surface.shape[1]) > 0.2:\n",
    "                        self.xys.append((fragment, x, y, W, H))\n",
    "        \n",
    "        self.train_aug_list = [\n",
    "            # A.RandomSizedCrop(min_max_height=(1024, CROP_SIZE), height=CROP_SIZE, width=CROP_SIZE, always_apply=True),\n",
    "            A.Resize(IMAGE_SIZE, IMAGE_SIZE, always_apply=True),\n",
    "            # A.RandomScale(scale_limit=0.15, p=0.5),\n",
    "            \n",
    "            \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            # A.Cutout(max_h_size=int(IMAGE_SIZE * 0.02),\n",
    "            #          max_w_size=int(IMAGE_SIZE * 0.02), num_holes=4, p=0.9),\n",
    "            # A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "            # A.Cutout(max_h_size=int(IMAGE_SIZE * 0.05),\n",
    "            #          max_w_size=int(IMAGE_SIZE * 0.05), num_holes=4, p=0.7),\n",
    "            # A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "            # A.Cutout(max_h_size=int(IMAGE_SIZE * 0.1),\n",
    "            #          max_w_size=int(IMAGE_SIZE * 0.1), num_holes=4, p=0.7),\n",
    "            \n",
    "            # A.Cutout(max_h_size=int(IMAGE_SIZE * 0.15),\n",
    "            #          max_w_size=int(IMAGE_SIZE * 0.15), num_holes=2, p=0.7),\n",
    "            A.Rotate(limit=90, p=0.8),\n",
    "            \n",
    "            # A.OneOf([\n",
    "            #         A.GaussNoise(var_limit=[0.02, 0.1]),\n",
    "            #         A.GaussianBlur(),\n",
    "            #         A.MotionBlur(),\n",
    "            #         ], p=0.4),\n",
    "            \n",
    "            # A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "            # A.Transpose(p=0.5),\n",
    "            # A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "            # A.RandomContrast(p=0.5),\n",
    "            # A.RandomGamma(p=0.5),\n",
    "            ToTensorV2(transpose_mask=True),\n",
    "            \n",
    "            ]\n",
    "        \n",
    "        # self.train_aug_list = [\n",
    "        #         # A.RandomResizedCrop(\n",
    "        #         #     size, size, scale=(0.85, 1.0)),\n",
    "                \n",
    "        #         A.HorizontalFlip(p=0.5),\n",
    "        #         A.VerticalFlip(p=0.5),\n",
    "                \n",
    "        #         # A.RandomBrightnessContrast(p=0.75),\n",
    "        #         # A.CoarseDropout(max_holes=1, max_width=int(CROP_SIZE * 0.1), max_height=int(CROP_SIZE * 0.1), \n",
    "        #         #                 mask_fill_value=0, p=0.5),\n",
    "        #         # A.ShiftScaleRotate(p=0.75),\n",
    "                \n",
    "        #         A.Rotate(limit=90, p=0.9), \n",
    "                \n",
    "        #         # A.OneOf([\n",
    "        #         #         A.GaussNoise(var_limit=[1, 5]),\n",
    "        #         #         A.GaussianBlur(),\n",
    "        #         #         A.MotionBlur(),\n",
    "        #         #         ], p=0.4),\n",
    "        #         # A.GridDistortion(num_steps=1, distort_limit=0.3, p=0.5),\n",
    "                \n",
    "        #         # A.Cutout(max_h_size=int(CROP_SIZE * 0.2),\n",
    "        #         #          max_w_size=int(CROP_SIZE * 0.2), num_holes=1, p=1.0),\n",
    "        #         # A.Normalize(\n",
    "        #         #     mean= [0] * Z_DIMS,\n",
    "        #         #     std= [1] * Z_DIMS\n",
    "        #         # ),\n",
    "                \n",
    "                \n",
    "        #         ToTensorV2(transpose_mask=True),\n",
    "        #     ]\n",
    "        \n",
    "        # Create the augmentation pipeline\n",
    "        self.augmentations = A.Compose(self.train_aug_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        fragment, x1, y1, W, H = self.xys[i]\n",
    "        # take random Z_DIMS integers between 0 and Z_END, without repeating\n",
    "        # z_slices = np.random.choice(np.arange(8, Z_END), Z_DIMS, replace=False)\n",
    "        # # sort them\n",
    "        # z_slices = np.sort(z_slices)\n",
    "        \n",
    "        x_offset = random.randint(-600 if x1 != 0 else 0, 600)\n",
    "        y_offset = random.randint(-600 if y1 != 0 else 0, 600)\n",
    "        \n",
    "        x1 += x_offset\n",
    "        y1 += y_offset\n",
    "        \n",
    "        x2 = x1 + CROP_SIZE\n",
    "        y2 = y1 + CROP_SIZE\n",
    "        \n",
    "        if x2 > W:\n",
    "            x1 -= x_offset\n",
    "            x2 -= x_offset\n",
    "            \n",
    "        if y2 > H:\n",
    "            y1 -= y_offset\n",
    "            y2 -= y_offset\n",
    "        \n",
    "        # frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, z1:z2]\n",
    "        \n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, 1:Z_DIMS*2+1][:, :, ::2]\n",
    "        else:\n",
    "            frag_crop = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, 0:Z_DIMS*2  ][:, :, ::2]\n",
    "            \n",
    "        mask_crop = FRAGMENTS_ZARR[fragment].truth[y1:y2, x1:x2]\n",
    "        \n",
    "        # # take z_slices\n",
    "        # # Retrieve the crops\n",
    "        # frag_crop = []\n",
    "\n",
    "        # for z in z_slices:\n",
    "        #     frag_slice = FRAGMENTS_ZARR[fragment].surface_volume[y1:y2, x1:x2, z]\n",
    "        #     frag_crop.append(frag_slice)\n",
    "\n",
    "        # # Convert to numpy arrays\n",
    "        # frag_crop = np.array(frag_crop)\n",
    "        \n",
    "        # # permpute the axes: (z, y, x) -> (y, x, z)\n",
    "        # frag_crop = np.transpose(frag_crop, (1, 2, 0))\n",
    "        \n",
    "        \n",
    "        # if random.random() > 0.5:\n",
    "        #     frag_crop = np.flip(frag_crop, axis=1).copy()\n",
    "        #     mask_crop = np.flip(mask_crop, axis=1).copy()\n",
    "\n",
    "        # Perform train augmentations\n",
    "\n",
    "        frag_crop = frag_crop/65535.0\n",
    "        \n",
    "        \n",
    "        \n",
    "        if np.random.uniform(0, 1) < 0.5:\n",
    "            # Apply the augmentations\n",
    "            augmented = self.augmentations(image=frag_crop, mask=mask_crop)\n",
    "\n",
    "            # Separate the image and mask\n",
    "            frag_crop, mask_crop = augmented[\"image\"], augmented[\"mask\"]\n",
    "        else:\n",
    "            # Apply the augmentations\n",
    "            augmented = self.augmentations(image=1-frag_crop, mask=mask_crop)\n",
    "\n",
    "            # Separate the image and mask\n",
    "            frag_crop, mask_crop = augmented[\"image\"], augmented[\"mask\"]\n",
    "            frag_crop = 1-frag_crop\n",
    "            \n",
    "\n",
    "        # normalize\n",
    "        \n",
    "        # frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "        frag_crop = frag_crop.unsqueeze(0)\n",
    "        mask_crop = mask_crop.float().unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        return frag_crop, mask_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47375e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(1, 48, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172c2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.830830Z",
     "iopub.status.busy": "2023-05-22T15:19:14.830623Z",
     "iopub.status.idle": "2023-05-22T15:19:14.833824Z",
     "shell.execute_reply": "2023-05-22T15:19:14.833636Z"
    },
    "papermill": {
     "duration": 0.022963,
     "end_time": "2023-04-08T10:12:11.644387",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.621424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class VesuviusVal(Dataset):\n",
    "    def __init__(self, fragment):\n",
    "        self.fragment = FRAGMENTS_ZARR[fragment]\n",
    "        self.xys = []\n",
    "        \n",
    "        H, W = FRAGMENTS_SHAPE[fragment]\n",
    "        for y in range(0, H-CROP_SIZE+1, CROP_SIZE):\n",
    "            for x in range(0, W-CROP_SIZE+1, CROP_SIZE):\n",
    "                self.xys.append((x, y))\n",
    "                \n",
    "        self.valid_aug_list = [\n",
    "            A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "            ToTensorV2(transpose_mask=True),\n",
    "            ]\n",
    "        self.augmentations = A.Compose(self.valid_aug_list)\n",
    "                \n",
    "    def __getitem__(self, i):\n",
    "        x1, y1 = self.xys[i]\n",
    "        x2, y2 = x1+CROP_SIZE, y1+CROP_SIZE\n",
    "        \n",
    "        \n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            frag_crop = self.fragment.surface_volume[y1:y2, x1:x2, 1:int(Z_DIMS*2)+1][:, :, ::2]\n",
    "        else:\n",
    "            frag_crop = self.fragment.surface_volume[y1:y2, x1:x2, 0:int(Z_DIMS*2)  ][:, :, ::2]\n",
    "        mask_crop = self.fragment.truth[y1:y2, x1:x2]\n",
    "        \n",
    "        # if random.random() > 0.5:\n",
    "        #     frag_crop = np.flip(frag_crop, axis=1).copy()\n",
    "        #     mask_crop = np.flip(mask_crop, axis=1).copy()\n",
    "\n",
    "        # Perform train augmentations\n",
    "\n",
    "        frag_crop = frag_crop/65535.0\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # Apply the augmentations\n",
    "        augmented = self.augmentations(image=frag_crop, mask=mask_crop)\n",
    "\n",
    "        # Separate the image and mask\n",
    "        frag_crop, mask_crop = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        # normalize\n",
    "        \n",
    "        # frag_crop = (frag_crop - 0.45)/0.225\n",
    "        \n",
    "        frag_crop = frag_crop.float().unsqueeze(0)\n",
    "        mask_crop = mask_crop.float().unsqueeze(0)\n",
    "        \n",
    "        return frag_crop, mask_crop, torch.tensor([x1, y1, x2, y2], dtype=torch.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282f924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:14.835003Z",
     "iopub.status.busy": "2023-05-22T15:19:14.834854Z",
     "iopub.status.idle": "2023-05-22T15:19:18.753710Z",
     "shell.execute_reply": "2023-05-22T15:19:18.753470Z"
    },
    "papermill": {
     "duration": 0.019671,
     "end_time": "2023-04-08T10:12:11.672490",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.652819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = VesuviusTrain(TRAIN_FRAGMENTS)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=1,\n",
    "                              shuffle=True, pin_memory=True, drop_last=True)\n",
    "n_train = len(dataloader_train)\n",
    "\n",
    "dataset_valid = VesuviusVal(TEST_FRAGMENT)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=1,\n",
    "                              shuffle=False, pin_memory=True, drop_last=False)\n",
    "n_valid = len(dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577f1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:18.755094Z",
     "iopub.status.busy": "2023-05-22T15:19:18.754980Z",
     "iopub.status.idle": "2023-05-22T15:19:18.802862Z",
     "shell.execute_reply": "2023-05-22T15:19:18.802648Z"
    }
   },
   "outputs": [],
   "source": [
    "i = random.randint(0, len(dataset_train)-1)\n",
    "img, mask = dataset_train[i]\n",
    "print(img.min(), img.max())\n",
    "\n",
    "x = img[0]\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x[0], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask[0], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208b713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(dataset_valid)-1)\n",
    "print(i)\n",
    "img, mask, _ = dataset_valid[i]\n",
    "print(img.min(), img.max())\n",
    "\n",
    "x = img[0]\n",
    "print(x.shape)\n",
    "plt.imshow(x[0], cmap=\"gray\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdcc7e0b",
   "metadata": {
    "papermill": {
     "duration": 0.008028,
     "end_time": "2023-04-08T10:12:11.688860",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.680832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model\n",
    "* Encoder is a 3D ResNet model. The architecture has been modified to remove temporal downsampling between blocks.\n",
    "* A 2D decoder is used for predicting the segmentation map.\n",
    "* The encoder feature maps are average pooled over the Z dimension before passing it to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cc8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:18.804051Z",
     "iopub.status.busy": "2023-05-22T15:19:18.803936Z",
     "iopub.status.idle": "2023-05-22T15:19:18.807874Z",
     "shell.execute_reply": "2023-05-22T15:19:18.807665Z"
    },
    "papermill": {
     "duration": 0.023714,
     "end_time": "2023-04-08T10:12:11.721140",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.697426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder_dims, upscale):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(encoder_dims[i]+encoder_dims[i-1], encoder_dims[i-1], 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(encoder_dims[i-1]),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for i in range(1, len(encoder_dims))])\n",
    "\n",
    "        self.logit = nn.Conv2d(encoder_dims[0], 1, 1, 1, 0)\n",
    "        self.up = nn.Upsample(scale_factor=upscale, mode=\"bilinear\")\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        for i in range(len(feature_maps)-1, 0, -1):\n",
    "            f_up = F.interpolate(feature_maps[i], scale_factor=2, mode=\"bilinear\")\n",
    "            f = torch.cat([feature_maps[i-1], f_up], dim=1)\n",
    "            f_down = self.convs[i-1](f)\n",
    "            feature_maps[i-1] = f_down\n",
    "\n",
    "        x = self.logit(feature_maps[0])\n",
    "        mask = self.up(x)\n",
    "        return mask\n",
    "\n",
    "\n",
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = generate_model(model_depth=18, n_input_channels=1)\n",
    "        self.decoder = Decoder(encoder_dims=[64, 128, 256, 512], upscale=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat_maps = self.encoder(x)\n",
    "        feat_maps_pooled = [torch.mean(f, dim=2) for f in feat_maps]\n",
    "        pred_mask = self.decoder(feat_maps_pooled)\n",
    "        return pred_mask\n",
    "    \n",
    "    def load_pretrained_weights(self, state_dict):\n",
    "        # Convert 3 channel weights to single channel\n",
    "        # ref - https://timm.fast.ai/models#Case-1:-When-the-number-of-input-channels-is-1\n",
    "        conv1_weight = state_dict['conv1.weight']\n",
    "        state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "        print(self.encoder.load_state_dict(state_dict, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4a0f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:18.808831Z",
     "iopub.status.busy": "2023-05-22T15:19:18.808754Z",
     "iopub.status.idle": "2023-05-22T15:19:19.948272Z",
     "shell.execute_reply": "2023-05-22T15:19:19.947908Z"
    },
    "papermill": {
     "duration": 3.891528,
     "end_time": "2023-04-08T10:12:15.621016",
     "exception": false,
     "start_time": "2023-04-08T10:12:11.729488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SegModel()\n",
    "# model.load_pretrained_weights(torch.load(\"/home/viktor/Documents/kaggle/vesuvius-challenge/experiments/3D-resnet/r3d18_K_200ep.pth\")[\"state_dict\"])\n",
    "model.load_state_dict(torch.load(\"/home/viktor/Documents/kaggle/vesuvius-challenge/experiments/3D-resnet/exp-1-reproduce-training-with-augm-bce-dice-loss-size-768-data-augm-fold-1/ckpts/resnet18_3d_seg_epoch_202.pt\"))\n",
    "model = nn.DataParallel(model, device_ids=[0])\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e9288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:19.950331Z",
     "iopub.status.busy": "2023-05-22T15:19:19.950205Z",
     "iopub.status.idle": "2023-05-22T15:19:20.915384Z",
     "shell.execute_reply": "2023-05-22T15:19:20.915058Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5, 1, 16, 512, 512)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d84d7c0e",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2023-04-08T10:12:15.638951",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.630135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Competition metric (F0.5 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbeb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:20.916793Z",
     "iopub.status.busy": "2023-05-22T15:19:20.916703Z",
     "iopub.status.idle": "2023-05-22T15:19:20.919097Z",
     "shell.execute_reply": "2023-05-22T15:19:20.918897Z"
    },
    "papermill": {
     "duration": 0.020268,
     "end_time": "2023-04-08T10:12:15.668008",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.647740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "def fbeta_score(preds, targets, threshold, beta=0.5, smooth=1e-5):\n",
    "    preds_t = torch.where(preds > threshold, 1.0, 0.0).float()\n",
    "    \n",
    "    ctp = preds_t[targets==1].sum()\n",
    "    cfp = preds_t[targets==0].sum()\n",
    "    # False negatives\n",
    "    cfm = ((1 - preds) * targets).sum()\n",
    "\n",
    "    # Recall\n",
    "    \n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (ctp + cfm + smooth)\n",
    "    fbeta = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return fbeta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "639c9148",
   "metadata": {
    "papermill": {
     "duration": 0.008498,
     "end_time": "2023-04-08T10:12:15.685205",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.676707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca2e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:20.920350Z",
     "iopub.status.busy": "2023-05-22T15:19:20.920197Z",
     "iopub.status.idle": "2023-05-22T15:19:20.922350Z",
     "shell.execute_reply": "2023-05-22T15:19:20.922060Z"
    },
    "papermill": {
     "duration": 0.019067,
     "end_time": "2023-04-08T10:12:15.713237",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.694170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
    "                                                steps_per_epoch=40, epochs=EPOCHS//10,\n",
    "                                                pct_start=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77a022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:20.923488Z",
     "iopub.status.busy": "2023-05-22T15:19:20.923371Z",
     "iopub.status.idle": "2023-05-22T15:19:21.755443Z",
     "shell.execute_reply": "2023-05-22T15:19:21.755093Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "DiceLoss = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def fbeta_loss(y_pred, y_true, beta=0.5, smooth=1e-5):\n",
    "    \n",
    "    ctp = (y_pred * y_true).sum(dim=0)\n",
    "    cfp = (y_pred * (1 - y_true)).sum(dim=0)\n",
    "    cfn = ((1 - y_pred) * y_true).sum(dim=0)\n",
    "\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (ctp + cfn + smooth)\n",
    "    fbeta = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return -fbeta.mean()\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    # return fbeta_loss(y_pred, y_true)\n",
    "    return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304e1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:21.757058Z",
     "iopub.status.busy": "2023-05-22T15:19:21.756961Z",
     "iopub.status.idle": "2023-05-22T15:19:21.794864Z",
     "shell.execute_reply": "2023-05-22T15:19:21.794410Z"
    },
    "papermill": {
     "duration": 0.385175,
     "end_time": "2023-04-08T10:12:16.107159",
     "exception": false,
     "start_time": "2023-04-08T10:12:15.721984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_mask = torch.from_numpy(np.asarray(FRAGMENTS_ZARR[TEST_FRAGMENT].truth)).float().cuda()\n",
    "gt_shape = FRAGMENTS_SHAPE[TEST_FRAGMENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b85bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:21.796496Z",
     "iopub.status.busy": "2023-05-22T15:19:21.796409Z",
     "iopub.status.idle": "2023-05-22T15:19:21.798283Z",
     "shell.execute_reply": "2023-05-22T15:19:21.798091Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"training_log.txt\", level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00067c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:19:21.799518Z",
     "iopub.status.busy": "2023-05-22T15:19:21.799436Z",
     "iopub.status.idle": "2023-05-22T15:49:45.657000Z",
     "shell.execute_reply": "2023-05-22T15:49:45.656631Z"
    },
    "papermill": {
     "duration": 4077.588277,
     "end_time": "2023-04-08T11:20:13.706513",
     "exception": false,
     "start_time": "2023-04-08T10:12:16.118236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fbeta_best = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    # cur_lr = f\"LR : {scheduler.get_last_lr()[0]:.2E}\"\n",
    "    pbar_train = enumerate(dataloader_train)\n",
    "    pbar_train = tqdm(pbar_train, total=n_train, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    mloss_train, mloss_val, val_metric = 0.0, 0.0, 0.0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i, (fragments, masks) in pbar_train:\n",
    "        fragments, masks = fragments.cuda().half(), masks.cuda().half()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast():\n",
    "            pred_masks = model(fragments)\n",
    "            loss = criterion(pred_masks, masks)\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            mloss_train += loss.detach().item()\n",
    "\n",
    "        gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
    "        pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{EPOCHS}\", gpu_mem, LR,\n",
    "                                                              f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
    "        \n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    pbar_val = enumerate(dataloader_valid)\n",
    "    pbar_val = tqdm(pbar_val, total=n_valid, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    final_pred_mask = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    for i, (fragments, masks, xys) in pbar_val:\n",
    "        fragments, masks = fragments.cuda(), masks.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_masks = model(fragments)\n",
    "            mloss_val += criterion(pred_masks, masks).item()\n",
    "            pred_masks = torch.sigmoid(pred_masks)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for j, xy in enumerate(xys):\n",
    "            # resize pred_masks[j, 0] from (IMAGE_SIZE, IMAGE_SIZE) to (CROP_SIZE, CROP_SIZE) using albumentations\n",
    "            upsampled_pred_masks = cv2.resize(pred_masks[j, 0].cpu().numpy(), (CROP_SIZE, CROP_SIZE)).astype(np.float32)\n",
    "            final_pred_mask[xy[1]:xy[3], xy[0]:xy[2]] = torch.tensor(upsampled_pred_masks, device='cuda', dtype=torch.float32)\n",
    "\n",
    "        pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
    "    \n",
    "    out = {\n",
    "        'train_loss': mloss_train / n_train,\n",
    "        'val_loss': mloss_val / n_valid,\n",
    "    }\n",
    "    \n",
    "    for threshold in np.arange(0.2, 1.00, 0.05):\n",
    "        fbeta = fbeta_score(final_pred_mask, gt_mask, threshold)\n",
    "        print(f\"Threshold : {threshold:.2f}\\tFBeta : {fbeta:.6f}\")\n",
    "        \n",
    "        out[f'fbeta_{threshold:.2f}'] = fbeta.item()\n",
    "        if fbeta_best < fbeta:\n",
    "            fbeta_best = fbeta\n",
    "            torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_best_{fbeta_best:.4f}.pt\")\n",
    "    \n",
    "    out[\"epoch\"] = epoch\n",
    "    df_out = pd.DataFrame(out, index=[0])\n",
    "    \n",
    "    if epoch == 1:\n",
    "        !rm resnet18_3d_seg.csv\n",
    "        df_out.to_csv(\"resnet18_3d_seg.csv\", index=False)\n",
    "    else:\n",
    "        # first read the old csv file\n",
    "        df_old = pd.read_csv(\"resnet18_3d_seg.csv\")\n",
    "        # append the new row to it\n",
    "        df_new = pd.concat([df_old, df_out], ignore_index=True)\n",
    "        # save the new csv file\n",
    "        df_new.to_csv(\"resnet18_3d_seg.csv\", index=False)\n",
    "\n",
    "    torch.save(model.module.state_dict(), f\"./ckpts/resnet18_3d_seg_epoch_{epoch}.pt\")\n",
    "\n",
    "    # if epoch == 30:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ade36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89431087",
   "metadata": {
    "papermill": {
     "duration": 0.381515,
     "end_time": "2023-04-08T11:20:14.478012",
     "exception": false,
     "start_time": "2023-04-08T11:20:14.096497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4132.646938,
   "end_time": "2023-04-08T11:20:18.816611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-08T10:11:26.169673",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
